{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 15:43:36.461 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-06-06 15:43:36.463 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-06-06 15:43:36.465 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-06-06 15:43:36.466 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-06-06 15:43:36.468 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-06-06 15:43:36.469 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-06-06 15:43:36.469 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-06-06 15:43:36.470 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-06-06 15:43:36.472 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-06-06 15:43:36.473 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-06-06 15:43:36.474 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-06-06 15:43:36.475 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from veliadb import base, settings\n",
    "from veliadb import benchling_orm as bo\n",
    "from veliadb.base import (Session, Orf, OrfXref, Transcript, Gene, \n",
    "                          TranscriptOrf, SequenceRegionXref, Protein, \n",
    "                          ProteinXref, Dataset, ProteinOrf)\n",
    "\n",
    "from sqlalchemy.sql.expression import func, and_, or_\n",
    "\n",
    "from dashboard import data_load\n",
    "import pyarrow.parquet as pq\n",
    "from dashboard.etl import CACHE_DIR, TPM_DESEQ2_FACTOR, DATA_DIR\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = base.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16282850"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.query(Orf).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_orfs = session.query(Orf).filter(Orf.vtx_id != '').all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dashboard_orfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data Set (3): CCDS,\n",
       " Data Set (4): HGNC_ID,\n",
       " Data Set (5): HGNC_SYMBOL,\n",
       " Data Set (6): swissprot,\n",
       " Data Set (7): trembl,\n",
       " Data Set (10): RefSeqFE,\n",
       " Data Set (12): BestRefSeq%2CGnomon,\n",
       " Data Set (17): CHESS,\n",
       " Data Set (18): havana,\n",
       " Data Set (9): Gnomon,\n",
       " Data Set (11): cmsearch,\n",
       " Data Set (21): ensembl,\n",
       " Data Set (13): BestRefSeq,\n",
       " Data Set (23): FANTOM,\n",
       " Data Set (24): ensembl_havana,\n",
       " Data Set (2): HAVANA,\n",
       " Data Set (1): ENSEMBL,\n",
       " Data Set (14): Curated Genomic,\n",
       " Data Set (8): RefSeq,\n",
       " Data Set (29): StringTie,\n",
       " Data Set (16): tRNAscan-SE,\n",
       " Data Set (31): openprot,\n",
       " Data Set (81): velia_phase6_viral_sORF,\n",
       " Data Set (33): velia_phase1_secreted_smORFs,\n",
       " Data Set (34): velia_phase1_Prensner,\n",
       " Data Set (37): velia_phase2_Chothani2022_SignalP,\n",
       " Data Set (38): velia_phase2_lncRNA_Jen,\n",
       " Data Set (40): velia_phase1_Chen,\n",
       " Data Set (41): velia_phase5_autoimmune lncRNA,\n",
       " Data Set (43): velia_phase2_Mudge2022_SignalP,\n",
       " Data Set (96): velia_phase7_tcga-DE_conserved_signalp+,\n",
       " Data Set (97): velia_phase7_Ribo-seq_PBMC_LPS_R848,\n",
       " Data Set (46): velia_phase2_Rat_Cardiac_Huang,\n",
       " Data Set (94): Benchling - PurifiedProtein,\n",
       " Data Set (66): velia_phase2_83,\n",
       " Data Set (32): velia_phase1_Bona fide,\n",
       " Data Set (35): velia_phase2_Cao_Slavoff_MINAS60,\n",
       " Data Set (36): velia_phase3_nan,\n",
       " Data Set (70): velia_phase5_bona fide,\n",
       " Data Set (71): velia_phase2_Seung,\n",
       " Data Set (39): velia_phase5_uniprot-tremble,\n",
       " Data Set (42): velia_phase2_Chang_Saghatelian,\n",
       " Data Set (44): velia_phase2_Bianca_Chen,\n",
       " Data Set (45): velia_phase4_nan,\n",
       " Data Set (47): velia_phase2_Bonafide_Bianca,\n",
       " Data Set (48): velia_phase5_Blume_Mudge,\n",
       " Data Set (78): velia_phase6_autoimmune_gwas,\n",
       " Data Set (79): velia_phase6_public_mass_spec,\n",
       " Data Set (80): velia_phase6_plasma_mass_spec,\n",
       " Data Set (104): gencode_riboseq,\n",
       " Data Set (112): velia_phase9_Bona fide,\n",
       " Data Set (113): velia_phase9_Li et al VSMC,\n",
       " Data Set (114): velia_phase9_orfrater,\n",
       " Data Set (115): velia_phase9_Olsen,\n",
       " Data Set (116): velia_phase9_tcgaDE_esmPhylocsf,\n",
       " Data Set (122): velia_phase10_riboseq_230114,\n",
       " Data Set (124): HPA - Immune - neutrophil - nTPM,\n",
       " Data Set (125): HPA - Immune - basophil - nTPM,\n",
       " Data Set (126): HPA - Immune - naive CD8 T-cell - nTPM,\n",
       " Data Set (127): HPA - Immune - memory CD8 T-cell - nTPM,\n",
       " Data Set (128): HPA - Immune - memory B-cell - nTPM,\n",
       " Data Set (129): HPA - Immune - total PBMC - nTPM,\n",
       " Data Set (130): HPA - Immune - MAIT T-cell - nTPM,\n",
       " Data Set (131): HPA - Immune - gdT-cell - nTPM,\n",
       " Data Set (132): HPA - Immune - NK-cell - nTPM,\n",
       " Data Set (133): HPA - Immune - naive B-cell - nTPM,\n",
       " Data Set (134): HPA - Immune - non-classical monocyte - nTPM,\n",
       " Data Set (135): HPA - Immune - memory CD4 T-cell - nTPM,\n",
       " Data Set (136): HPA - Immune - plasmacytoid DC - nTPM,\n",
       " Data Set (137): HPA - Immune - naive CD4 T-cell - nTPM,\n",
       " Data Set (138): HPA - Immune - myeloid DC - nTPM,\n",
       " Data Set (139): HPA - Immune - intermediate monocyte - nTPM,\n",
       " Data Set (140): HPA - Immune - T-reg - nTPM,\n",
       " Data Set (141): HPA - Immune - classical monocyte - nTPM,\n",
       " Data Set (142): HPA - Immune - eosinophil - nTPM,\n",
       " Data Set (143): velia_phase11_riboseq_240214,\n",
       " Data Set (145): MetaORF v1.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.query(Dataset).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(session.query(Orf.vtx_id, OrfXref.xref).join(OrfXref).filter(and_(OrfXref.xref_dataset_id == 145,\n",
    "                                                           OrfXref.type == 'score',)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_vtx = list(score_df[score_df['xref'].astype(float) < .95]['vtx_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22820"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([d.vtx_id for d in dashboard_orfs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../cache_updates/all_vtx_240606.txt', 'w') as outfile:\n",
    "    for orf in dashboard_orfs:\n",
    "        if orf.vtx_id in low_vtx:\n",
    "            continue\n",
    "        else:\n",
    "            outfile.write(f'{orf.vtx_id}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swissprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "swissprot_query = \\\n",
    "    session.query(Protein, Orf)\\\n",
    "           .join(ProteinXref, ProteinXref.protein_id == Protein.id)\\\n",
    "           .join(Dataset, Dataset.id == ProteinXref.xref_dataset_id)\\\n",
    "           .join(ProteinOrf, ProteinOrf.protein_id == Protein.id)\\\n",
    "           .join(Orf, Orf.id == ProteinOrf.orf_id)\\\n",
    "           .filter(Dataset.name == 'swissprot')\\\n",
    "           .filter(func.length(Protein.aa_seq) < 150)\\\n",
    "           .distinct(ProteinXref.protein_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "alan_df = pd.read_csv('../../data/orfs_under_150codons_with_function-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../cache_updates/swissprot_sORF_150aa_vtx.txt', 'w') as outfile:\n",
    "    for prot, orf in swissprot_query.all():\n",
    "        outfile.write(f'VTX-{orf.id:07d}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot, orf = swissprot_query.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2621462385.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    prot.\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "prot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENSP00000319240.2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot.ensembl_protein_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENSP00000319240.2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orf.ensembl_protein_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187319"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.query(ProteinOrf).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dashboard.etl.dashboard_etl import parse_deepsig, parse_phobius, parse_signalp41, par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{OUTPUT_PREFIX}/phobius.results.txt', 'r') as fopen:\n",
    "    phobius_data = ''.join(fopen.readlines())\n",
    "phobius_results = parse_phobius(phobius_data, seqs)\n",
    "deep_tmhmm_results = parse_deeptmhmm(f'{OUTPUT_PREFIX}/biolib_results/predicted_topologies.3line')\n",
    "signalp_6_results = parse_signalp6(f'{OUTPUT_PREFIX}/output.json', seqs)\n",
    "signalp_5_results = parse_signalp5(f'{OUTPUT_PREFIX}/results_summary.signalp5', seqs)\n",
    "with open(f'{OUTPUT_PREFIX}/signalp41.results.txt', 'r') as fopen:\n",
    "    signalp41_data = ''.join(fopen.readlines())\n",
    "signalp_41_results = parse_signalp41(signalp41_data, seqs)\n",
    "deepsig_results = parse_deepsig(f'{OUTPUT_PREFIX}/deepsig.results', seqs)\n",
    "\n",
    "deepsig_results = pd.DataFrame(deepsig_results).T\n",
    "signalp_6_results = pd.DataFrame(signalp_6_results).T\n",
    "signalp_5_results = pd.DataFrame(signalp_5_results).T\n",
    "signalp_41_results = pd.DataFrame(signalp_41_results).T\n",
    "phobius_results = pd.DataFrame(phobius_results).T\n",
    "deep_tmhmm_results = pd.DataFrame(deep_tmhmm_results).T\n",
    "string_representations = pd.DataFrame()\n",
    "string_representations['Deepsig'] = deepsig_results['string_rep']\n",
    "string_representations['SignalP 6slow'] = signalp_6_results['string_rep']\n",
    "string_representations['SignalP 5b'] = signalp_5_results['string_rep']\n",
    "string_representations['SignalP 4.1'] = signalp_41_results['string_rep']\n",
    "string_representations['Phobius'] = phobius_results['string_rep']\n",
    "string_representations['DeepTMHMM'] = deep_tmhmm_results['string_rep']\n",
    "\n",
    "vtx_ids = []\n",
    "df_ordr = []\n",
    "for k, v in seqs.items():\n",
    "    vtx_ids.append(k)\n",
    "    df_ordr.append(v)\n",
    "string_representations = string_representations.loc[df_ordr].copy()\n",
    "string_representations.index = vtx_ids\n",
    "string_representations['Sequence'] = [seqs[i] for i in string_representations.index]\n",
    "\n",
    "string_representations.to_csv(f'{OUTPUT_PREFIX}/sequence_features_strings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
